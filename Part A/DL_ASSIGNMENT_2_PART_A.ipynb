{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"M2HnzwZ5VByd"},"outputs":[],"source":["# %cd drive/MyDrive/dl-assigment-2/\n","\n","# !unzip nature_12K.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:44:24.426489Z","iopub.status.busy":"2024-03-31T09:44:24.425643Z","iopub.status.idle":"2024-03-31T09:44:37.709319Z","shell.execute_reply":"2024-03-31T09:44:37.708227Z","shell.execute_reply.started":"2024-03-31T09:44:24.426453Z"},"trusted":true},"outputs":[],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:44:54.359100Z","iopub.status.busy":"2024-03-31T09:44:54.358335Z","iopub.status.idle":"2024-03-31T09:45:03.490904Z","shell.execute_reply":"2024-03-31T09:45:03.489945Z","shell.execute_reply.started":"2024-03-31T09:44:54.359066Z"},"id":"Zf1EZbdVTaIi","trusted":true},"outputs":[],"source":["import cv2\n","import glob\n","import random\n","import numpy as np\n","import torch\n","from pandas.core.common import flatten\n","torch.manual_seed(7)\n","torch.cuda.empty_cache()\n","from torchvision import transforms\n","from torch.utils.data import DataLoader,Dataset\n","from PIL import Image\n","from torch import  nn,optim\n","import torch.nn.functional as F\n","from tqdm import tqdm \n","import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:03.492724Z","iopub.status.busy":"2024-03-31T09:45:03.492438Z","iopub.status.idle":"2024-03-31T09:45:06.323072Z","shell.execute_reply":"2024-03-31T09:45:06.321968Z","shell.execute_reply.started":"2024-03-31T09:45:03.492698Z"},"trusted":true},"outputs":[],"source":["!wandb login my_id"]},{"cell_type":"markdown","metadata":{},"source":["# Helper Functions and Constants"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# constants\n","IMG_MODE = 'RGB'\n","TRAIN_LABEL = 'train'\n","TEST_LABEL = 'test'\n","DATASET_PATH = '/kaggle/input/nature-12k/inaturalist_12K/'\n","TEST_DATA_PATH = f'{DATASET_PATH}val/'\n","TRAIN_DATA_PATH = f'{DATASET_PATH}val/'\n","\n","# activation function\n","RELU_KEY = 'ReLU'\n","LEAKY_RELU_KEY = 'LeakyReLU'\n","GELU_KEY = 'GELU'\n","SILU_KEY = 'SiLU'\n","MISH_KEY = 'Mish'\n","ELU_KEY = 'ELU'\n","\n","# wandb constants\n","WANDB_PROJECT_NAME=\"dl-assignment-2\"\n","WANDB_ENTITY_NAME=\"cs23m007\"\n","\n","# wandb sweep param labels\n","NUMBER_FILTER_KEY = \"number_filters\"\n","ACTIVATION_FUNCTION_KEY = \"activation\"\n","FILTER_ORGANIZATION_KEY = \"filter_organization\"\n","DATA_AUGMENTATION_KEY = \"data_aug\"\n","BATCH_NORMALIZATION_KEY = \"batch_norm\"\n","DROPOUT_KEY = \"dropout\"\n","BATCH_SIZE_KEY = \"batch_size\"\n","EPOCHS_KEY = \"epochs\"\n","LEARNING_RATE_KEY = \"learning_rate\"\n","SIZE_FILTER_KEY = \"size_filters\"\n","DENSE_LAYER_NEURONS_KEY = \"neurons_in_dense_layer\"\n","\n","# wandb plot titles\n","TRAIN_ACCURACY_TITLE = \"train_acc\"\n","VALIDATION_ACCURACY_TITLE = \"val_acc\"\n","TEST_ACCURACY_TITLE = \"test_acc\"\n","TRAIN_LOSS_TITLE = \"train_loss\"\n","VALIDATION_LOSS_TITLE = \"val_loss\"\n","TEST_LOSS_TITLE = \"test_loss\"\n","\n","TRAIN_DATASET_SPLIT_RATIO = 0.8\n","\n","def convertIntoPercentage(x,n,digit=4):\n","    return round((x / n) * 100, digit)\n","\n","def evaluate(device, loader, model):\n","    \"\"\"\n","    Evaluate the performance of a neural network model on a dataset.\n","\n","    Parameters:\n","        device (torch.device): The device to run the evaluation on (e.g., CPU or GPU).\n","        loader (torch.utils.data.DataLoader): DataLoader for loading batches of data.\n","        model (torch.nn.Module): The neural network model to evaluate.\n","\n","    Returns:\n","        Tuple[float, float]: Accuracy and average loss of the model on the dataset.\n","    \"\"\"\n","\n","    # Initialize variables to keep track of correct predictions and total samples\n","    Y_cap_num,N_val = 0,0\n","    loss = 0\n","    \n","    # Set the model to evaluation mode\n","    model.eval()\n","    \n","    # Disable gradient calculation since no training is done during evaluation\n","    with torch.no_grad():\n","        for X, Y in tqdm(loader, total=len(loader)):\n","            X,Y = X.to(device=device),Y.to(device=device)\n","            \n","            # Forward pass: compute predicted outputs by passing inputs through the model\n","            Y_cap = model(X)\n","            loss += nn.CrossEntropyLoss()(Y_cap, Y).item()\n","\n","            _, predictions = Y_cap.max(1)\n","\n","            N_val = N_val + predictions.size(0)\n","            \n","            Y_cap_num = Y_cap_num +  (predictions == Y).sum().item()\n","\n","    # Calculate accuracy and average loss\n","    acc = convertIntoPercentage(Y_cap_num , N_val)\n","    loss = loss/N_val\n","    return acc, loss\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Pre Processing"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:08.709470Z","iopub.status.busy":"2024-03-31T09:45:08.708506Z","iopub.status.idle":"2024-03-31T09:45:08.725306Z","shell.execute_reply":"2024-03-31T09:45:08.724186Z","shell.execute_reply.started":"2024-03-31T09:45:08.709432Z"},"id":"grem9A74d4Gd","trusted":true},"outputs":[],"source":["class iNaturalist(Dataset):\n","    def __init__(self, image_paths, class_to_idx, transform):\n","        self.all_images = image_paths\n","        self.current_transform = transform\n","        self.class_to_idx = class_to_idx\n","        \n","    def __len__(self):\n","        return len(self.all_images)\n","\n","    def __getitem__(self, idx):\n","        image_filepath = self.all_images[idx]\n","        image = cv2.imread(image_filepath)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        \n","        y = self.class_to_idx[image_filepath.split('/')[-2]]\n","        \n","        X = Image.fromarray(np.uint8(image)).convert(IMG_MODE)\n","        X = Image.fromarray(image.astype('uint8'), IMG_MODE)\n","        X = self.current_transform(X)\n","\n","        return X, y\n","\n","def create_data(data_type, data_path,  data_aug, image_shape, b_size):\n","    \"\"\"\n","    Create DataLoader objects for training or testing data.\n","\n","    Parameters:\n","        data_type (str): Type of data ('TRAIN_LABEL' or 'TEST_LABEL').\n","        data_path (str): Path to the directory containing the image data.\n","        data_aug (bool): Whether to apply data augmentation or not.\n","        image_shape (tuple): Desired shape of the input images (height, width).\n","        batch_size (int): Number of samples per batch.\n","\n","    Returns:\n","        torch.utils.data.DataLoader: DataLoader object for the specified data type.\n","    \"\"\"\n","\n","    # Get the list of class names from the directory structure\n","    classes = [image_path.split('/')[-1] for image_path in glob.glob(data_path + '/*')]\n","\n","    # Get paths of all images\n","    all_images = [glob.glob(image_path + '/*') for image_path in glob.glob(data_path + '/*')]\n","    all_images = list(flatten(all_images))\n","\n","    idx_to_class,class_to_idx = dict(),dict()\n","    for i, j in enumerate(classes):\n","        idx_to_class[i] = j\n","        class_to_idx[j] = i\n","\n","    # Define image transformations for non-augmented data\n","    non_aug_tran = transforms.Compose([transforms.Resize((image_shape)),\n","                                transforms.ToTensor()\n","                                    ])\n","    if data_type == TEST_LABEL:\n","        test_image_paths=all_images\n","        test_dataset= iNaturalist(test_image_paths,class_to_idx,non_aug_tran)\n","        test_loader = DataLoader(test_dataset, batch_size=b_size, shuffle=True)\n","\n","        return test_loader\n","\n","    # Shuffle all image paths to randomly split into training and validation sets\n","    random.shuffle(all_images)\n","\n","    tr_paths, v_paths = all_images[:int(TRAIN_DATASET_SPLIT_RATIO*len(all_images))], all_images[int(TRAIN_DATASET_SPLIT_RATIO*len(all_images)):] \n","\n","    # Create datasets for training and validation\n","    tr_data,v_data = iNaturalist(tr_paths,class_to_idx,non_aug_tran),iNaturalist(v_paths,class_to_idx,non_aug_tran)\n","\n","    if data_aug:\n","        augu_tran = transforms.Compose([transforms.Resize((image_shape)),\n","                transforms.RandomRotation(degrees=30),\n","                transforms.RandomHorizontalFlip(p=0.5),\n","                transforms.RandomGrayscale(p=0.2),\n","                transforms.ToTensor(),\n","                            ])\n","\n","        tr_data = iNaturalist(tr_paths,class_to_idx,augu_tran)\n","        v_data = iNaturalist(v_paths,class_to_idx,augu_tran)  \n","    # Create DataLoader objects for training and validation\n","    t_loader,v_loader = DataLoader(tr_data, batch_size=b_size, shuffle=True),DataLoader(v_data, batch_size=b_size, shuffle=True)\n","    return t_loader,v_loader\n"]},{"cell_type":"markdown","metadata":{},"source":["# CNN Model Class"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:11.760780Z","iopub.status.busy":"2024-03-31T09:45:11.760419Z","iopub.status.idle":"2024-03-31T09:45:11.784353Z","shell.execute_reply":"2024-03-31T09:45:11.783474Z","shell.execute_reply.started":"2024-03-31T09:45:11.760750Z"},"trusted":true},"outputs":[],"source":["class ConvolutionBlocks(nn.Module):\n","    \"\"\"\n","    A class representing a series of convolutional blocks with optional batch normalization and activation functions.\n","\n","    Parameters:\n","        activation (torch.nn.Module): Activation function to be applied after each convolutional layer.\n","        batch_norm (bool): Flag indicating whether to use batch normalization.\n","        size_filters (list): List of kernel sizes for each convolutional layer.\n","        filter_organization (float): Factor by which the number of filters increases in subsequent layers.\n","        number_filters (int): Number of filters in the first convolutional layer.\n","        num_conv_layers (int): Number of convolutional layers.\n","\n","    Attributes:\n","        activationFn (torch.nn.Module): Activation function to be applied after each convolutional layer.\n","        num_filters (list): List to store the number of filters in each layer.\n","        batch_norm (bool): Flag indicating whether to use batch normalization.\n","        conv1 to conv5 (torch.nn.Conv2d): Convolutional layers.\n","        pool (torch.nn.MaxPool2d): Max pooling layer.\n","        batchnorm1 to batchnorm5 (torch.nn.BatchNorm2d): Batch normalization layers.\n","\n","    Methods:\n","        forward(x): Forward pass through the convolutional blocks.\n","\n","    \"\"\"\n","    def __init__(self, activation, batch_norm, size_filters, filter_organization, number_filters,num_conv_layers):\n","        super().__init__()\n","\n","        # Initialize attributes\n","        self.activationFn=activation\n","        self.num_filters=[number_filters]\n","        self.batch_norm=batch_norm\n","\n","        # Calculate number of filters for each layer\n","        for i in range(1,num_conv_layers):\n","            self.num_filters.append(int(self.num_filters[i-1]*filter_organization))\n","        \n","        # Define convolutional layers\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=self.num_filters[0],kernel_size=size_filters[0],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv2 = nn.Conv2d(in_channels=self.num_filters[0],out_channels=self.num_filters[1],kernel_size=size_filters[1],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv3 = nn.Conv2d(in_channels=self.num_filters[1],out_channels=self.num_filters[2],kernel_size=size_filters[2],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv4 = nn.Conv2d(in_channels=self.num_filters[2],out_channels=self.num_filters[3],kernel_size=size_filters[3],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv5 = nn.Conv2d(in_channels=self.num_filters[3],out_channels=self.num_filters[4],kernel_size=size_filters[4],stride=(1, 1),padding=(1, 1),bias=False)\n","\n","        # Define max pooling layer\n","        self.pool  = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","\n","        # Define batch normalization layers if batch_norm is True\n","        self.batchnorm1 = nn.BatchNorm2d(self.num_filters[0])\n","        self.batchnorm2 = nn.BatchNorm2d(self.num_filters[1])\n","        self.batchnorm3 = nn.BatchNorm2d(self.num_filters[2])\n","        self.batchnorm4 = nn.BatchNorm2d(self.num_filters[3])\n","        self.batchnorm5 = nn.BatchNorm2d(self.num_filters[4])\n","\n","    def forward(self, x):\n","        \"\"\"\n","        Perform forward pass through the convolutional blocks.\n","\n","        Parameters:\n","            x (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output tensor after passing through the convolutional blocks.\n","        \"\"\"\n","        if not self.batch_norm: # If batch normalization is not used\n","            x=self.pool(self.activationFn(self.conv1(x)))\n","            x=self.pool(self.activationFn(self.conv2(x)))\n","            x=self.pool(self.activationFn(self.conv3(x)))\n","            x=self.pool(self.activationFn(self.conv4(x)))\n","            x=self.pool(self.activationFn(self.conv5(x)))\n","            return x\n","        else: # If batch normalization is used\n","            x= self.pool(self.activationFn(self.batchnorm1(self.conv1(x))))\n","            x= self.pool(self.activationFn(self.batchnorm2(self.conv2(x))))\n","            x= self.pool(self.activationFn(self.batchnorm3(self.conv3(x))))\n","            x= self.pool(self.activationFn(self.batchnorm4(self.conv4(x))))\n","            x= self.pool(self.activationFn(self.batchnorm5(self.conv5(x))))\n","            return x\n","\n","class Model(nn.Module):\n","    \"\"\"\n","    A class representing a convolutional neural network model.\n","\n","    Parameters:\n","        image_shape (tuple): Shape of the input images (height, width, channels).\n","        dropout (float): Dropout probability for regularization.\n","        activation (str): Name of the activation function to be used.\n","        batch_norm (bool): Flag indicating whether to use batch normalization in convolutional blocks.\n","        size_filters (list): List of kernel sizes for each convolutional layer.\n","        filter_organization (float): Factor by which the number of filters increases in subsequent layers.\n","        number_filters (int): Number of filters in the first convolutional layer.\n","        neurons_in_dense_layer (int): Number of neurons in the dense (fully connected) layer.\n","        num_conv_layers (int): Number of convolutional layers.\n","\n","    Attributes:\n","        activation (torch.nn.Module): Activation function to be applied throughout the model.\n","        conv_blocks (ConvolutionBlocks): Object representing a series of convolutional blocks.\n","        fully_conn_layer_1 (torch.nn.Linear): Fully connected layer.\n","        output_layer (torch.nn.Linear): Output layer.\n","        dropout (torch.nn.Dropout): Dropout layer.\n","        num_conv_layers (int): Number of convolutional layers.\n","\n","    Methods:\n","        forward(x): Forward pass through the model.\n","\n","    \"\"\"\n","\n","    def __init__(self, image_shape,dropout , activation, batch_norm, size_filters, filter_organization, \n","                  number_filters , neurons_in_dense_layer,num_conv_layers):\n","        super().__init__()\n","\n","        # Define activation function based on the provided name\n","        activationFn = {\n","            RELU_KEY : nn.ReLU(),\n","            LEAKY_RELU_KEY : nn.LeakyReLU(),\n","            GELU_KEY : nn.GELU(),\n","            SILU_KEY : nn.SiLU(),\n","            MISH_KEY : nn.Mish(),\n","            ELU_KEY : nn.ELU()\n","        }\n","        self.activation = activationFn[activation]\n","\n","        # Initialize convolutional blocks\n","        self.conv_blocks = ConvolutionBlocks(activation = self.activation,\n","                                             batch_norm= batch_norm,\n","                                             size_filters= size_filters,\n","                                             filter_organization= filter_organization,\n","                                             number_filters= number_filters,\n","                                             num_conv_layers= num_conv_layers)\n","        \n","        # Calculate the size of the output of convolutional blocks\n","        sz=self.conv_blocks(torch.zeros(*(image_shape))).data.shape\n","\n","        # Define fully connected layer\n","        self.fully_conn_layer_1   = nn.Linear(sz[1] * sz[2] * sz[3],neurons_in_dense_layer,bias=True)  \n","\n","        # Define output layer\n","        self.output_layer= nn.Linear(neurons_in_dense_layer,10,bias=True)   \n","\n","        # Define dropout layer\n","        self.dropout=nn.Dropout(p=dropout)\n","        self.num_conv_layers = num_conv_layers\n","    def forward(self, x):\n","        \"\"\"\n","        Perform forward pass through the model.\n","\n","        Parameters:\n","            x (torch.Tensor): Input tensor.\n","\n","        Returns:\n","            torch.Tensor: Output tensor after passing through the model.\n","        \"\"\"\n","        x = self.conv_blocks(x)\n","\n","        # Apply dropout and activation to the fully connected layer\n","        x = self.dropout(self.activation(self.fully_conn_layer_1(x.reshape(x.shape[0],-1))))\n","\n","        # Apply softmax activation to the output layer\n","        x = F.softmax(self.output_layer(x),dim=1)\n","        return x\n"]},{"cell_type":"markdown","metadata":{},"source":["# Training Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def train():\n","    \"\"\"\n","    Train the neural network model using the specified configurations and hyperparameters.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","    torch.cuda.empty_cache()\n","\n","    # Define image shape and data paths\n","    image_shape = (1,3,224,224)\n","    test_data_path = TEST_DATA_PATH\n","    train_data_path = TRAIN_DATA_PATH\n","\n","    # Define default configuration parameters\n","    config_defaults = dict({\n","      EPOCHS_KEY : 10,\n","      BATCH_SIZE_KEY: 64,\n","      ACTIVATION_FUNCTION_KEY: RELU_KEY,\n","      LEARNING_RATE_KEY:0.001,\n","      DROPOUT_KEY: 0.3,\n","      BATCH_NORMALIZATION_KEY: True,\n","      DATA_AUGMENTATION_KEY: True,\n","      SIZE_FILTER_KEY:[7,5,5,3,3],\n","      FILTER_ORGANIZATION_KEY: 2,\n","      NUMBER_FILTER_KEY: 16,\n","      DENSE_LAYER_NEURONS_KEY: 512\n","    })\n","\n","    wandb.init(project=WANDB_PROJECT_NAME, entity=WANDB_ENTITY_NAME,config = config_defaults)\n","    args = wandb.config\n","\n","    # Set the name of the run\n","    wandb.run.name = 'ep-'+str(args[EPOCHS_KEY])+'-lr-'+str(args[LEARNING_RATE_KEY])+'-bs-'+str(args[BATCH_SIZE_KEY])+'-act-'+str(args[ACTIVATION_FUNCTION_KEY])+'-drt-'+str(args[DROPOUT_KEY]) \\\n","                      +'-bn-'+ str(args[BATCH_NORMALIZATION_KEY])+ '-da-'+str(args[DATA_AUGMENTATION_KEY])+'-filt_sizes-'+str(args[SIZE_FILTER_KEY]) \\\n","                      + '-filt_org-'+str(args[FILTER_ORGANIZATION_KEY])+'-ini_filt'+str(args[NUMBER_FILTER_KEY])+'-n_d-'+str(args[DENSE_LAYER_NEURONS_KEY])\n","\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    \n","    # Initialize the model\n","    model = Model(image_shape= image_shape,\n","                  dropout= args[DROPOUT_KEY],\n","                  activation= args[ACTIVATION_FUNCTION_KEY],\n","                  batch_norm= args[BATCH_NORMALIZATION_KEY],\n","                  size_filters= args[SIZE_FILTER_KEY],\n","                  filter_organization= args[FILTER_ORGANIZATION_KEY],\n","                  number_filters= args[NUMBER_FILTER_KEY],\n","                  neurons_in_dense_layer= args[DENSE_LAYER_NEURONS_KEY],\n","                  num_conv_layers= 5\n","                ).to(device)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=args[LEARNING_RATE_KEY])\n","\n","    # Iterate over batches in training data\n","    for epoch in range(args[EPOCHS_KEY]):\n","        model.train()\n","        test_loader = create_data(TEST_LABEL,test_data_path,args[DATA_AUGMENTATION_KEY], image_shape[2:], args[BATCH_SIZE_KEY])\n","        train_loader, valid_loader = create_data(TRAIN_LABEL,train_data_path,args[DATA_AUGMENTATION_KEY],image_shape[2:], args[BATCH_SIZE_KEY])\n","\n","        train_correct, train_loss = 0, 0\n","        total_samples = 0\n","        for batch_id,(data,label) in enumerate(tqdm(train_loader)):\n","          \n","            data = data.to(device=device)\n","            targets = label.to(device=device)\n","\n","            scores = model(data)\n","            loss = nn.CrossEntropyLoss()(scores, targets)\n","            train_loss += loss.item()\n","            \n","            _, predictions = scores.max(1)\n","            train_correct += (predictions == targets).sum()\n","            total_samples +=  predictions.size(0)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","        \n","        train_loss /= total_samples\n","        train_acc = round((train_correct / total_samples).item()  * 100, 4)\n","        \n","       \n","        \n","        val_acc, val_loss = evaluate(device, valid_loader, model)\n","        test_acc, test_loss = evaluate(device, test_loader, model)\n","        \n","        wandb.log(\n","          {TRAIN_ACCURACY_TITLE: train_acc, VALIDATION_ACCURACY_TITLE: val_acc, TEST_ACCURACY_TITLE: test_acc, TRAIN_LOSS_TITLE: train_loss, VALIDATION_LOSS_TITLE: val_loss, TEST_LOSS_TITLE: test_loss}\n","        )\n","\n","        print('\\nEpoch ', epoch, TRAIN_ACCURACY_TITLE, train_acc, VALIDATION_ACCURACY_TITLE, val_acc, TEST_ACCURACY_TITLE, test_acc, TRAIN_LOSS_TITLE, train_loss, VALIDATION_LOSS_TITLE, val_loss, TEST_LOSS_TITLE, test_loss) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:38:18.918545Z","iopub.status.busy":"2024-03-31T09:38:18.918112Z","iopub.status.idle":"2024-03-31T09:38:18.926813Z","shell.execute_reply":"2024-03-31T09:38:18.925470Z","shell.execute_reply.started":"2024-03-31T09:38:18.918510Z"},"trusted":true},"outputs":[],"source":["'''\n","config = {\n","    EPOCHS_KEY : 10,\n","    BATCH_SIZE_KEY: 64,\n","    ACTIVATION_FUNCTION_KEY: RELU_KEY,\n","    LEARNING_RATE_KEY:0.001,\n","    DROPOUT_KEY: 0.3,\n","    BATCH_NORMALIZATION_KEY: True,\n","    DATA_AUGMENTATION_KEY: True,\n","    SIZE_FILTER_KEY:[7,5,5,3,3],\n","    FILTER_ORGANIZATION_KEY: 2,\n","    NUMBER_FILTER_KEY: 16,\n","    DENSE_LAYER_NEURONS_KEY: 512\n","}\n","class DotDict:\n","    def __init__(self, dictionary):\n","        self.__dict__.update(dictionary)\n","\n","args = DotDict(config)\n","train(args)\n","'''"]},{"cell_type":"markdown","metadata":{},"source":["# Run Wandb Sweep"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:23.292348Z","iopub.status.busy":"2024-03-31T09:45:23.291980Z","iopub.status.idle":"2024-03-31T09:45:25.441004Z","shell.execute_reply":"2024-03-31T09:45:25.440056Z","shell.execute_reply.started":"2024-03-31T09:45:23.292318Z"},"trusted":true},"outputs":[],"source":["# wandb.login()\n","sweep_config = {\n","    \"name\" : \"Assignment2_Part_A_Q2\",\n","    \"method\" : \"bayes\",\n","    'metric': {\n","        'name': VALIDATION_ACCURACY_TITLE,\n","        'goal': 'maximize'\n","    },\n","    \"parameters\" : {\n","        NUMBER_FILTER_KEY: {\n","            'values': [16, 32, 64, 128]\n","        },\n","        ACTIVATION_FUNCTION_KEY: {\n","            'values': [RELU_KEY, LEAKY_RELU_KEY,GELU_KEY,SILU_KEY,MISH_KEY,ELU_KEY]\n","        },\n","        FILTER_ORGANIZATION_KEY: {\n","            'values': [1, 2, 0.5]\n","        },\n","        DATA_AUGMENTATION_KEY: {\n","              \"values\": [True,False]\n","        },\n","        BATCH_NORMALIZATION_KEY: {\n","              \"values\": [True,False]\n","        },\n","        DROPOUT_KEY: {\n","            \"values\": [0,0.1,0.2,0.3]\n","        },\n","        BATCH_SIZE_KEY: {\n","            \"values\": [32, 64, 128]\n","        },\n","        EPOCHS_KEY : {\n","            \"values\" : [10, 15, 20 , 25 , 30]\n","        },\n","        LEARNING_RATE_KEY:{\n","            \"values\": [0.001,0.0001,0.0003,0.0005]\n","        },\n","        SIZE_FILTER_KEY:{\n","            'values': [[7,5,5,3,3], [11,9,7,5,3]]\n","        },\n","        DENSE_LAYER_NEURONS_KEY: {\n","            \"values\": [32, 64, 128, 256, 512, 1024]\n","        }        \n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=WANDB_PROJECT_NAME, entity=WANDB_ENTITY_NAME)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:33.633869Z","iopub.status.busy":"2024-03-31T09:45:33.632799Z","iopub.status.idle":"2024-03-31T09:53:47.758411Z","shell.execute_reply":"2024-03-31T09:53:47.757194Z","shell.execute_reply.started":"2024-03-31T09:45:33.633829Z"},"trusted":true},"outputs":[],"source":["wandb.agent(sweep_id, train, count = 50)\n","wandb.finish()"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4693720,"sourceId":7975703,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
