{"cells":[{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T16:17:51.325074Z","iopub.status.busy":"2024-04-02T16:17:51.324706Z","iopub.status.idle":"2024-04-02T16:17:51.333614Z","shell.execute_reply":"2024-04-02T16:17:51.332652Z","shell.execute_reply.started":"2024-04-02T16:17:51.325044Z"},"trusted":true},"outputs":[],"source":["import cv2\n","import glob\n","import random\n","import numpy as np\n","import torch\n","from pandas.core.common import flatten\n","torch.manual_seed(7)\n","torch.cuda.empty_cache()\n","import torchvision\n","from torchvision import transforms\n","from torch.utils.data import DataLoader,Dataset\n","from PIL import Image\n","from torch import nn,optim\n","import torch.nn.functional as F\n","from tqdm import tqdm \n","import wandb\n"]},{"cell_type":"markdown","metadata":{},"source":["# Helper Functions and Constants"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T16:17:54.224760Z","iopub.status.busy":"2024-04-02T16:17:54.223860Z","iopub.status.idle":"2024-04-02T16:17:54.230116Z","shell.execute_reply":"2024-04-02T16:17:54.229138Z","shell.execute_reply.started":"2024-04-02T16:17:54.224725Z"},"trusted":true},"outputs":[],"source":["# constants\n","IMG_MODE = 'RGB'\n","TRAIN_LABEL = 'train'\n","TEST_LABEL = 'test'\n","DATASET_PATH = '/kaggle/input/nature-12k/inaturalist_12K/'\n","TEST_DATA_PATH = f'{DATASET_PATH}val/'\n","TRAIN_DATA_PATH = f'{DATASET_PATH}train/'\n","\n","# activation function\n","RELU_KEY = 'ReLU'\n","LEAKY_RELU_KEY = 'LeakyReLU'\n","GELU_KEY = 'GELU'\n","SILU_KEY = 'SiLU'\n","MISH_KEY = 'Mish'\n","ELU_KEY = 'ELU'\n","\n","# wandb constants\n","WANDB_PROJECT_NAME=\"dl-assignment-2\"\n","WANDB_ENTITY_NAME=\"cs23m007\"\n","\n","# wandb sweep param labels\n","NUMBER_FILTER_KEY = \"number_filters\"\n","ACTIVATION_FUNCTION_KEY = \"activation\"\n","FILTER_ORGANIZATION_KEY = \"filter_organization\"\n","DATA_AUGMENTATION_KEY = \"data_aug\"\n","BATCH_NORMALIZATION_KEY = \"batch_norm\"\n","DROPOUT_KEY = \"dropout\"\n","BATCH_SIZE_KEY = \"batch_size\"\n","EPOCHS_KEY = \"epochs\"\n","LEARNING_RATE_KEY = \"learning_rate\"\n","SIZE_FILTER_KEY = \"size_filters\"\n","DENSE_LAYER_NEURONS_KEY = \"neurons_in_dense_layer\"\n","PRETRAINED_KEY = \"pretrained\"\n","\n","# wandb plot titles\n","TRAIN_ACCURACY_TITLE = \"train_acc\"\n","VALIDATION_ACCURACY_TITLE = \"val_acc\"\n","TEST_ACCURACY_TITLE = \"test_acc\"\n","TRAIN_LOSS_TITLE = \"train_loss\"\n","VALIDATION_LOSS_TITLE = \"val_loss\"\n","TEST_LOSS_TITLE = \"test_loss\"\n","\n","# Ratio to split train and validation 0.8 means 80% train data and 20% validation data\n","TRAIN_DATASET_SPLIT_RATIO = 0.8\n","\n","# Best paramters get by running sweep with different parameters\n","best_params = dict({\n","    ACTIVATION_FUNCTION_KEY: RELU_KEY,\n","    BATCH_NORMALIZATION_KEY: True,\n","    BATCH_SIZE_KEY: 128,\n","    DATA_AUGMENTATION_KEY: False,\n","    DROPOUT_KEY: 0.1,\n","    EPOCHS_KEY : 30,\n","    FILTER_ORGANIZATION_KEY: 2,\n","    LEARNING_RATE_KEY:0.0001,\n","    DENSE_LAYER_NEURONS_KEY: 512,\n","    NUMBER_FILTER_KEY: 32,\n","    SIZE_FILTER_KEY:[11,9,7,5,3]\n","})\n","\n","class DotDict:\n","    \"\"\"\n","    Used to convert dict to an object\n","    \"\"\"\n","    def __init__(self, dictionary):\n","        self.__dict__.update(dictionary)\n","\n","def convertIntoPercentage(x,n,digit=4):\n","    return round((x / n) * 100, digit)\n","\n","def evaluate(device, loader, model):\n","    \"\"\"\n","    Evaluate the performance of a neural network model on a dataset.\n","\n","    Parameters:\n","        device (torch.device): The device to run the evaluation on (e.g., CPU or GPU).\n","        loader (torch.utils.data.DataLoader): DataLoader for loading batches of data.\n","        model (torch.nn.Module): The neural network model to evaluate.\n","\n","    Returns:\n","        Tuple[float, float]: Accuracy and average loss of the model on the dataset.\n","    \"\"\"\n","\n","    # Initialize variables to keep track of correct predictions and total samples\n","    Y_cap_num,N_val = 0,0\n","    loss = 0\n","    \n","    # Set the model to evaluation mode\n","    model.eval()\n","    \n","    # Disable gradient calculation since no training is done during evaluation\n","    with torch.no_grad():\n","        for X, Y in tqdm(loader, total=len(loader)):\n","            X,Y = X.to(device=device),Y.to(device=device)\n","            \n","            # Forward pass: compute predicted outputs by passing inputs through the model\n","            Y_cap = model(X)\n","            loss += nn.CrossEntropyLoss()(Y_cap, Y).item()\n","\n","            _, predictions = Y_cap.max(1)\n","\n","            N_val = N_val + predictions.size(0)\n","            \n","            Y_cap_num = Y_cap_num +  (predictions == Y).sum().item()\n","\n","    # Calculate accuracy and average loss\n","    acc = convertIntoPercentage(Y_cap_num , N_val)\n","    loss = loss/N_val\n","    return acc, loss\n","\n","def freeze_layers(model, freeze_k):\n","    \"\"\"\n","    Freeze layers in a PyTorch model up to a certain depth.\n","\n","    Parameters:\n","        model (torch.nn.Module): The PyTorch model whose layers are to be frozen.\n","        freeze_k (int): The index of the last layer to freeze. If freeze_k is -1,\n","                       all layers will be frozen.\n","\n","    Returns:\n","        None\n","    \"\"\"\n","\n","    # If freeze_k is -1, freeze all layers\n","    if freeze_k == -1: \n","        for param in model.parameters():\n","            param.requires_grad = False\n","    else:\n","        # Initialize a counter to keep track of the layers\n","        k = 0\n","\n","        # Iterate over model parameters\n","        for param in model.parameters():\n","            k += 1\n","            param.requires_grad = False\n","            \n","            # If reached the specified depth, stop freezing layers\n","            if k > freeze_k:\n","                return\n"]},{"cell_type":"markdown","metadata":{},"source":["# Data Pre Processing"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T16:17:56.219412Z","iopub.status.busy":"2024-04-02T16:17:56.219063Z","iopub.status.idle":"2024-04-02T16:17:56.234377Z","shell.execute_reply":"2024-04-02T16:17:56.233350Z","shell.execute_reply.started":"2024-04-02T16:17:56.219383Z"},"trusted":true},"outputs":[],"source":["class iNaturalist(Dataset):\n","    \"\"\"\n","    Custom dataset class for iNaturalist dataset.\n","\n","    Parameters:\n","        image_paths (list): List of file paths to images.\n","        class_to_idx (dict): Dictionary mapping class names to indices.\n","        transform (callable): A function/transform to apply to the images.\n","    \"\"\"\n","    def __init__(self, image_paths, class_to_idx, transform):\n","        \"\"\"\n","        Initialize the dataset with image paths, class mappings, and transformation.\n","\n","        Args:\n","            image_paths (list): List of file paths to images.\n","            class_to_idx (dict): Dictionary mapping class names to indices.\n","            transform (callable): A function/transform to apply to the images.\n","        \"\"\"\n","        self.all_images = image_paths\n","        self.current_transform = transform\n","        self.class_to_idx = class_to_idx\n","        \n","    def __len__(self):\n","        \"\"\"\n","        Get the total number of samples in the dataset.\n","\n","        Returns:\n","            int: Total number of samples in the dataset.\n","        \"\"\"\n","        return len(self.all_images)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        Get a sample from the dataset at the given index.\n","\n","        Args:\n","            idx (int): Index of the sample to retrieve.\n","\n","        Returns:\n","            tuple: A tuple containing the image and its corresponding label.\n","        \"\"\"\n","\n","        image_filepath = self.all_images[idx]\n","\n","        # Read the image using OpenCV and convert color from BGR to RGB\n","        image = cv2.imread(image_filepath)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        # Extract the label (class index) from the image file path using class_to_idx mapping\n","        y = self.class_to_idx[image_filepath.split('/')[-2]]\n","        \n","        # Convert the image array to PIL Image and apply the current transformation\n","        X = Image.fromarray(np.uint8(image)).convert(IMG_MODE)\n","        X = self.current_transform(X)\n","\n","        return X, y\n","\n","def create_data(data_type, data_path,  data_aug, image_shape, b_size):\n","    \"\"\"\n","    Create DataLoader objects for training or testing data.\n","\n","    Parameters:\n","        data_type (str): Type of data ('TRAIN_LABEL' or 'TEST_LABEL').\n","        data_path (str): Path to the directory containing the image data.\n","        data_aug (bool): Whether to apply data augmentation or not.\n","        image_shape (tuple): Desired shape of the input images (height, width).\n","        batch_size (int): Number of samples per batch.\n","\n","    Returns:\n","        torch.utils.data.DataLoader: DataLoader object for the specified data type.\n","    \"\"\"\n","\n","    # Get the list of class names from the directory structure\n","    classes = [image_path.split('/')[-1] for image_path in glob.glob(data_path + '/*')]\n","\n","    # Get paths of all images\n","    all_images = [glob.glob(image_path + '/*') for image_path in glob.glob(data_path + '/*')]\n","    all_images = list(flatten(all_images))\n","\n","    idx_to_class,class_to_idx = dict(),dict()\n","    for i, j in enumerate(classes):\n","        idx_to_class[i] = j\n","        class_to_idx[j] = i\n","\n","    # Define image transformations for non-augmented data\n","    non_aug_tran = transforms.Compose([transforms.Resize((image_shape)),\n","                                transforms.ToTensor()\n","                                    ])\n","    if data_type == TEST_LABEL:\n","        test_image_paths=all_images\n","        test_dataset= iNaturalist(test_image_paths,class_to_idx,non_aug_tran)\n","        test_loader = DataLoader(test_dataset, batch_size=b_size, shuffle=True)\n","\n","        return test_loader\n","\n","    # Shuffle all image paths to randomly split into training and validation sets\n","    random.shuffle(all_images)\n","\n","    tr_paths, v_paths = all_images[:int(TRAIN_DATASET_SPLIT_RATIO*len(all_images))], all_images[int(TRAIN_DATASET_SPLIT_RATIO*len(all_images)):] \n","\n","    # Create datasets for training and validation\n","    tr_data,v_data = iNaturalist(tr_paths,class_to_idx,non_aug_tran),iNaturalist(v_paths,class_to_idx,non_aug_tran)\n","\n","    if data_aug:\n","        augu_tran = transforms.Compose([transforms.Resize((image_shape)),\n","                transforms.RandomRotation(degrees=30),\n","                transforms.RandomHorizontalFlip(p=0.5),\n","                transforms.RandomGrayscale(p=0.2),\n","                transforms.ToTensor(),\n","                            ])\n","\n","        tr_data = iNaturalist(tr_paths,class_to_idx,augu_tran)\n","        v_data = iNaturalist(v_paths,class_to_idx,augu_tran)  \n","    # Create DataLoader objects for training and validation\n","    t_loader,v_loader = DataLoader(tr_data, batch_size=b_size, shuffle=True),DataLoader(v_data, batch_size=b_size, shuffle=True)\n","    return t_loader,v_loader\n"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T16:18:27.760783Z","iopub.status.busy":"2024-04-02T16:18:27.760412Z","iopub.status.idle":"2024-04-02T16:18:27.779350Z","shell.execute_reply":"2024-04-02T16:18:27.778507Z","shell.execute_reply.started":"2024-04-02T16:18:27.760755Z"},"trusted":true},"outputs":[],"source":["def inception_v3_model(config_defaults = dict({\n","        EPOCHS_KEY : 10,\n","        BATCH_SIZE_KEY: 64,\n","        LEARNING_RATE_KEY:0.001,\n","        DATA_AUGMENTATION_KEY: True,\n","        PRETRAINED_KEY: True,\n","    }),isWandb=True):\n","    \"\"\"\n","    Train the neural network model using the specified configurations and hyperparameters.\n","\n","    Parameters:\n","    config_defaults (dict): Default parameter contain best parameters for model.\n","    isWandb (bool): if we don't want to use wandb to log report than pass False\n","\n","    Returns:\n","        model\n","    \"\"\"\n","\n","    torch.cuda.empty_cache()\n","    image_shape = (1,3,299,299)\n","    test_data_path = TEST_DATA_PATH\n","    train_data_path = TRAIN_DATA_PATH\n","\n","    args = DotDict(config_defaults)\n","\n","    if isWandb:\n","        wandb.init(project=WANDB_PROJECT_NAME, entity=WANDB_ENTITY_NAME,config = config_defaults)\n","        args = wandb.config\n","\n","        wandb.run.name = 'ep-'+str(args.epochs)+'-lr-'+str(args.learning_rate)+'-bs-'+str(args.batch_size) \\\n","             + '-da-'+str(args.data_aug) +'-pretrained-'+str(args.pretrained)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model = torchvision.models.inception_v3(pretrained=args[PRETRAINED_KEY], progress=True)\n","    freeze_layers(model, -1)\n","    model.AuxLogits.fc = nn.Linear(768, 10,bias=True)\n","    model.fc = nn.Linear(2048, 10, bias=True)\n","    model.to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=args[LEARNING_RATE_KEY])\n","\n","    for epoch in range(args.epochs):\n","        model.train()\n","        test_loader = create_data(TEST_LABEL,test_data_path,args[DATA_AUGMENTATION_KEY], image_shape[2:], args[BATCH_SIZE_KEY])\n","        train_loader, valid_loader = create_data(TRAIN_LABEL,train_data_path,args[DATA_AUGMENTATION_KEY],image_shape[2:], args[BATCH_SIZE_KEY])\n","\n","        train_correct, train_loss = 0, 0\n","        total_samples = 0\n","        for batch_id,(data,label) in enumerate(tqdm(train_loader)):\n","          \n","            data = data.to(device=device)\n","            targets = label.to(device=device)\n","\n","            loss = nn.CrossEntropyLoss()(scores, targets)\n","            train_loss += loss.item()\n","            scores = model(data)\n","            scores, _ = scores\n","            scores = F.softmax(scores, dim=1)\n","            \n","            _, predictions = scores.max(1)\n","            train_correct += (predictions == targets).sum()\n","            total_samples +=  predictions.size(0)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","        \n","        train_loss /= total_samples\n","        train_acc = round((train_correct / total_samples).item()  * 100, 4)\n","        \n","       \n","        \n","        val_acc, val_loss = evaluate(device, valid_loader, model)\n","        test_acc, test_loss = evaluate(device, test_loader, model)\n","        \n","        if isWandb:\n","            wandb.log(\n","            {TRAIN_ACCURACY_TITLE: train_acc, VALIDATION_ACCURACY_TITLE: val_acc, TEST_ACCURACY_TITLE: test_acc, TRAIN_LOSS_TITLE: train_loss, VALIDATION_LOSS_TITLE: val_loss, TEST_LOSS_TITLE: test_loss}\n","            )\n","\n","        print('\\nEpoch ', epoch, TRAIN_ACCURACY_TITLE, train_acc, VALIDATION_ACCURACY_TITLE, val_acc, TEST_ACCURACY_TITLE, test_acc, TRAIN_LOSS_TITLE, train_loss, VALIDATION_LOSS_TITLE, val_loss, TEST_LOSS_TITLE, test_loss) \n","    return model"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-04-02T16:18:29.457178Z","iopub.status.busy":"2024-04-02T16:18:29.456817Z","iopub.status.idle":"2024-04-02T17:02:47.346163Z","shell.execute_reply":"2024-04-02T17:02:47.345233Z","shell.execute_reply.started":"2024-04-02T16:18:29.457148Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [03:40<00:00,  1.77s/it]\n","100%|██████████| 32/32 [00:54<00:00,  1.70s/it]\n","100%|██████████| 32/32 [00:52<00:00,  1.65s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  0 train_acc 50.7938 val_acc 65.55 test_acc 72.4 train_loss 0.0323438434723631 val_loss 0.01788201892375946 test_loss 0.014509680956602097\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n","100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  1 train_acc 63.3454 val_acc 70.05 test_acc 73.2 train_loss 0.029587824861173825 val_loss 0.01583439415693283 test_loss 0.013816677093505859\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:54<00:00,  1.40s/it]\n","100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  2 train_acc 64.7706 val_acc 70.3 test_acc 73.6 train_loss 0.028991271591377283 val_loss 0.0165112287402153 test_loss 0.013816834419965745\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n","100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  3 train_acc 66.5208 val_acc 69.85 test_acc 74.0 train_loss 0.028635007722003114 val_loss 0.01720824798941612 test_loss 0.014112378269433975\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:52<00:00,  1.38s/it]\n","100%|██████████| 32/32 [00:42<00:00,  1.33s/it]\n","100%|██████████| 32/32 [00:40<00:00,  1.27s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  4 train_acc 66.1583 val_acc 70.35 test_acc 73.75 train_loss 0.02853098781813173 val_loss 0.01785410898923874 test_loss 0.01429168337583542\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:54<00:00,  1.39s/it]\n","100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  5 train_acc 67.0084 val_acc 70.9 test_acc 74.5 train_loss 0.02840820233931257 val_loss 0.017545974761247633 test_loss 0.014676217988133431\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n","100%|██████████| 32/32 [00:43<00:00,  1.37s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  6 train_acc 67.3584 val_acc 69.55 test_acc 74.3 train_loss 0.02831272870872241 val_loss 0.018731735587120057 test_loss 0.014827657535672188\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n","100%|██████████| 32/32 [00:43<00:00,  1.35s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  7 train_acc 68.096 val_acc 71.05 test_acc 74.6 train_loss 0.02813640453320978 val_loss 0.017756592839956283 test_loss 0.015395456999540329\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:55<00:00,  1.40s/it]\n","100%|██████████| 32/32 [00:42<00:00,  1.34s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.30s/it]\n"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  8 train_acc 67.2334 val_acc 72.65 test_acc 75.55 train_loss 0.028251597636609484 val_loss 0.017476197153329848 test_loss 0.015068569540977478\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 125/125 [02:53<00:00,  1.39s/it]\n","100%|██████████| 32/32 [00:43<00:00,  1.36s/it]\n","100%|██████████| 32/32 [00:41<00:00,  1.31s/it]"]},{"name":"stdout","output_type":"stream","text":["\n","Epoch  9 train_acc 68.196 val_acc 70.45 test_acc 75.55 train_loss 0.028061425988413956 val_loss 0.019049924194812776 test_loss 0.015233190611004829\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["inception_v3_model()"]},{"cell_type":"markdown","metadata":{},"source":["#### "]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4693720,"sourceId":7975703,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
