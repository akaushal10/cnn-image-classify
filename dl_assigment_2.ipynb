{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"M2HnzwZ5VByd"},"outputs":[],"source":["# %cd drive/MyDrive/dl-assigment-2/\n","\n","# !unzip nature_12K.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:44:24.426489Z","iopub.status.busy":"2024-03-31T09:44:24.425643Z","iopub.status.idle":"2024-03-31T09:44:37.709319Z","shell.execute_reply":"2024-03-31T09:44:37.708227Z","shell.execute_reply.started":"2024-03-31T09:44:24.426453Z"},"trusted":true},"outputs":[],"source":["!pip install wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:44:54.359100Z","iopub.status.busy":"2024-03-31T09:44:54.358335Z","iopub.status.idle":"2024-03-31T09:45:03.490904Z","shell.execute_reply":"2024-03-31T09:45:03.489945Z","shell.execute_reply.started":"2024-03-31T09:44:54.359066Z"},"id":"Zf1EZbdVTaIi","trusted":true},"outputs":[],"source":["import cv2\n","import glob\n","import random\n","import numpy as np\n","import torch\n","from pandas.core.common import flatten\n","torch.manual_seed(7)\n","torch.cuda.empty_cache()\n","from torchvision import transforms\n","from torch.utils.data import DataLoader,Dataset\n","from PIL import Image\n","from torch import  nn,optim\n","import torch.nn.functional as F\n","from tqdm import tqdm \n","import wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:03.492724Z","iopub.status.busy":"2024-03-31T09:45:03.492438Z","iopub.status.idle":"2024-03-31T09:45:06.323072Z","shell.execute_reply":"2024-03-31T09:45:06.321968Z","shell.execute_reply.started":"2024-03-31T09:45:03.492698Z"},"trusted":true},"outputs":[],"source":["!wandb login my_id"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:08.709470Z","iopub.status.busy":"2024-03-31T09:45:08.708506Z","iopub.status.idle":"2024-03-31T09:45:08.725306Z","shell.execute_reply":"2024-03-31T09:45:08.724186Z","shell.execute_reply.started":"2024-03-31T09:45:08.709432Z"},"id":"grem9A74d4Gd","trusted":true},"outputs":[],"source":["# constants\n","IMG_MODE = 'RGB'\n","TRAIN_LABEL = 'train'\n","TEST_LABEL = 'test'\n","\n","class iNaturalist(Dataset):\n","    def __init__(self, image_paths, class_to_idx, transform):\n","        self.all_images = image_paths\n","        self.current_transform = transform\n","        self.class_to_idx = class_to_idx\n","        \n","    def __len__(self):\n","        return len(self.all_images)\n","\n","    def __getitem__(self, idx):\n","        image_filepath = self.all_images[idx]\n","        image = cv2.imread(image_filepath)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        \n","        y = self.class_to_idx[image_filepath.split('/')[-2]]\n","        \n","        X = Image.fromarray(np.uint8(image)).convert(IMG_MODE)\n","        X = Image.fromarray(image.astype('uint8'), IMG_MODE)\n","        X = self.current_transform(X)\n","\n","        return X, y\n","\n","def create_data(data_type, data_path,  data_aug, image_shape, b_size):\n","    classes = [image_path.split('/')[-1] for image_path in glob.glob(data_path + '/*')]\n","\n","    all_images = [glob.glob(image_path + '/*') for image_path in glob.glob(data_path + '/*')]\n","    all_images = list(flatten(all_images))\n","\n","    idx_to_class,class_to_idx = dict(),dict()\n","    for i, j in enumerate(classes):\n","        idx_to_class[i] = j\n","        class_to_idx[j] = i\n","\n","    non_aug_tran = transforms.Compose([transforms.Resize((image_shape)),\n","                                transforms.ToTensor()\n","                                    ])\n","    if data_type == TEST_LABEL:\n","        test_image_paths=all_images\n","        test_dataset= iNaturalist(test_image_paths,class_to_idx,non_aug_tran)\n","        test_loader = DataLoader(test_dataset, batch_size=b_size, shuffle=True)\n","\n","        return test_loader\n","\n","\n","    random.shuffle(all_images)\n","\n","    tr_paths, v_paths = all_images[:int(0.8*len(all_images))], all_images[int(0.8*len(all_images)):] \n","\n","    tr_data,v_data = iNaturalist(tr_paths,class_to_idx,non_aug_tran),iNaturalist(v_paths,class_to_idx,non_aug_tran)\n","\n","    if data_aug:\n","        augu_tran = transforms.Compose([transforms.Resize((image_shape)),\n","                transforms.RandomRotation(degrees=30),\n","                transforms.RandomHorizontalFlip(p=0.5),\n","                transforms.RandomGrayscale(p=0.2),\n","                transforms.ToTensor(),\n","                            ])\n","\n","        tr_data = iNaturalist(tr_paths,class_to_idx,augu_tran)\n","        v_data = iNaturalist(v_paths,class_to_idx,augu_tran)  \n","\n","    t_loader,v_loader = DataLoader(tr_data, batch_size=b_size, shuffle=True),DataLoader(v_data, batch_size=b_size, shuffle=True)\n","    return t_loader,v_loader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:11.760780Z","iopub.status.busy":"2024-03-31T09:45:11.760419Z","iopub.status.idle":"2024-03-31T09:45:11.784353Z","shell.execute_reply":"2024-03-31T09:45:11.783474Z","shell.execute_reply.started":"2024-03-31T09:45:11.760750Z"},"trusted":true},"outputs":[],"source":["class ConvolutionBlocks(nn.Module):\n","    def __init__(self, activation, batch_norm, size_filters, filter_organization, number_filters,num_conv_layers):\n","        super().__init__()\n","        self.activationFn=activation\n","        self.num_filters=[number_filters]\n","        self.batch_norm=batch_norm\n","        for i in range(1,num_conv_layers):\n","            self.num_filters.append(int(self.num_filters[i-1]*filter_organization))\n","        self.conv1 = nn.Conv2d(in_channels=3,out_channels=self.num_filters[0],kernel_size=size_filters[0],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv2 = nn.Conv2d(in_channels=self.num_filters[0],out_channels=self.num_filters[1],kernel_size=size_filters[1],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv3 = nn.Conv2d(in_channels=self.num_filters[1],out_channels=self.num_filters[2],kernel_size=size_filters[2],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv4 = nn.Conv2d(in_channels=self.num_filters[2],out_channels=self.num_filters[3],kernel_size=size_filters[3],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.conv5 = nn.Conv2d(in_channels=self.num_filters[3],out_channels=self.num_filters[4],kernel_size=size_filters[4],stride=(1, 1),padding=(1, 1),bias=False)\n","        self.pool  = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n","        self.batchnorm1 = nn.BatchNorm2d(self.num_filters[0])\n","        self.batchnorm2 = nn.BatchNorm2d(self.num_filters[1])\n","        self.batchnorm3 = nn.BatchNorm2d(self.num_filters[2])\n","        self.batchnorm4 = nn.BatchNorm2d(self.num_filters[3])\n","        self.batchnorm5 = nn.BatchNorm2d(self.num_filters[4])\n","\n","    def forward(self, x):\n","        if self.batch_norm == False: \n","            x=self.pool(self.activationFn(self.conv1(x)))\n","            x=self.pool(self.activationFn(self.conv2(x)))\n","            x=self.pool(self.activationFn(self.conv3(x)))\n","            x=self.pool(self.activationFn(self.conv4(x)))\n","            x=self.pool(self.activationFn(self.conv5(x)))\n","            return x\n","        else:\n","            x= self.pool(self.activationFn(self.batchnorm1(self.conv1(x))))\n","            x= self.pool(self.activationFn(self.batchnorm2(self.conv2(x))))\n","            x= self.pool(self.activationFn(self.batchnorm3(self.conv3(x))))\n","            x= self.pool(self.activationFn(self.batchnorm4(self.conv4(x))))\n","            x= self.pool(self.activationFn(self.batchnorm5(self.conv5(x))))\n","            return x\n","\n","class Model(nn.Module):\n","    def __init__(self, image_shape,dropout , activation, batch_norm, size_filters, filter_organization, \n","                  number_filters , neurons_in_dense_layer,num_conv_layers):\n","        super().__init__()\n","        activationFn = {\n","            \"ReLU\" : nn.ReLU(),\n","            \"LeakyReLU\" : nn.LeakyReLU(),\n","            \"GELU\" : nn.GELU(),\n","            \"SiLU\" : nn.SiLU(),\n","            \"Mish\" : nn.Mish(),\n","            \"ELU\" : nn.ELU()\n","        }\n","        self.activation = activationFn[activation]\n","        self.conv_blocks = ConvolutionBlocks(activation = self.activation,\n","                                             batch_norm= batch_norm,\n","                                             size_filters= size_filters,\n","                                             filter_organization= filter_organization,\n","                                             number_filters= number_filters,\n","                                             num_conv_layers= num_conv_layers)\n","\n","        sz=self.conv_blocks(torch.zeros(*(image_shape))).data.shape\n","        self.fully_conn_layer_1   = nn.Linear(sz[1] * sz[2] * sz[3],neurons_in_dense_layer,bias=True)  \n","        self.output_layer= nn.Linear(neurons_in_dense_layer,10,bias=True)   \n","        self.dropout=nn.Dropout(p=dropout)\n","        self.num_conv_layers = num_conv_layers\n","    def forward(self, x):\n","        x = self.conv_blocks(x)\n","        x = self.dropout(self.activation(self.fully_conn_layer_1(x.reshape(x.shape[0],-1))))\n","        x = F.softmax(self.output_layer(x),dim=1)\n","        return x\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:14.992540Z","iopub.status.busy":"2024-03-31T09:45:14.992161Z","iopub.status.idle":"2024-03-31T09:45:15.014421Z","shell.execute_reply":"2024-03-31T09:45:15.013443Z","shell.execute_reply.started":"2024-03-31T09:45:14.992510Z"},"trusted":true},"outputs":[],"source":["def convertIntoPercentage(x,n,digit=4):\n","    return round((x / n) * 100, digit)\n","\n","def evaluate(device, loader, model):\n","    ''' Function to calculate accuracy to see performance of our model '''\n","        \n","    Y_cap_num,N_val = 0,0\n","    loss = 0\n","\n","    model.eval()\n","\n","    with torch.no_grad():\n","        for X, Y in tqdm(loader, total=len(loader)):\n","            X,Y = X.to(device=device),Y.to(device=device)\n","\n","            Y_cap = model(X)\n","            loss += nn.CrossEntropyLoss()(Y_cap, Y).item()\n","\n","            _, predictions = Y_cap.max(1)\n","\n","            N_val = N_val + predictions.size(0)\n","            \n","            Y_cap_num = Y_cap_num +  (predictions == Y).sum().item()\n","           \n","    acc = convertIntoPercentage(Y_cap_num , N_val)\n","    loss = loss/N_val\n","    return acc, loss\n","\n","def train():\n","\n","    torch.cuda.empty_cache()\n","    image_shape = (1,3,224,224)\n","    test_data_path = '/kaggle/input/nature-12k/inaturalist_12K/val/'\n","    train_data_path = '/kaggle/input/nature-12k/inaturalist_12K/train/'\n","    config_defaults = dict({\n","        \"epochs\" : 10,\n","        \"batch_size\": 64,\n","        'activation': 'relu',\n","        'learning_rate':0.001,\n","        \"dropout\": 0.3,\n","        \"batch_norm\": True,\n","        \"data_aug\": True,\n","        'size_filters':[7,5,5,3,3],\n","        'filter_organization': 2,\n","        'number_filters': 16,\n","        \"neurons_in_dense_layer\": 512\n","    })\n","\n","    wandb.init(project=\"dl-assignment-2\", entity=\"cs23m007\",config = config_defaults)\n","    args = wandb.config\n","\n","    wandb.run.name = 'ep-'+str(args.epochs)+'-lr-'+str(args.learning_rate)+'-bs-'+str(args.batch_size)+'-act-'+str(args.activation)+'-drt-'+str(args.dropout) \\\n","                      +'-bn-'+ str(args.batch_norm)+ '-da-'+str(args.data_aug)+'-filt_sizes-'+str(args.size_filters) \\\n","                      + '-filt_org-'+str(args.filter_organization)+'-ini_filt'+str(args.number_filters)+'-n_d-'+str(args.neurons_in_dense_layer)\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    model = Model(image_shape= image_shape,\n","                  dropout= args.dropout,\n","                  activation= args.activation,\n","                  batch_norm= args.batch_norm,\n","                  size_filters= args.size_filters,\n","                  filter_organization= args.filter_organization,\n","                  number_filters= args.number_filters,\n","                  neurons_in_dense_layer= args.neurons_in_dense_layer,\n","                  num_conv_layers= 5\n","                ).to(device)\n","\n","    optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n","\n","    for epoch in range(args.epochs):\n","        model.train()\n","        test_loader = create_data(\"test\",test_data_path,args.data_aug, image_shape[2:], args.batch_size)\n","        train_loader, valid_loader = create_data(\"train\",train_data_path,args.data_aug,image_shape[2:], args.batch_size)\n","\n","        train_correct, train_loss = 0, 0\n","        total_samples = 0\n","        for batch_id,(data,label) in enumerate(tqdm(train_loader)):\n","          \n","            data = data.to(device=device)\n","            targets = label.to(device=device)\n","\n","            scores = model(data)\n","            loss = nn.CrossEntropyLoss()(scores, targets)\n","            train_loss += loss.item()\n","            \n","            _, predictions = scores.max(1)\n","            train_correct += (predictions == targets).sum()\n","            total_samples +=  predictions.size(0)\n","            \n","            optimizer.zero_grad()\n","            loss.backward()\n","\n","            optimizer.step()\n","\n","        \n","        train_loss /= total_samples\n","        train_acc = round((train_correct / total_samples).item()  * 100, 4)\n","        \n","       \n","        \n","        val_acc, val_loss = evaluate(device, valid_loader, model)\n","        test_acc, test_loss = evaluate(device, test_loader, model)\n","        \n","        wandb.log(\n","          {'train_acc': train_acc, 'val_acc': val_acc, 'test_acc': test_acc, 'train_loss': train_loss, 'val_loss': val_loss, 'test_loss': test_loss}\n","        )\n","\n","        print('\\nEpoch ', epoch, 'train_acc', train_acc, 'val_acc', val_acc, 'test_acc', test_acc, 'train_loss', train_loss, 'val_loss', val_loss, 'test_loss', test_loss) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:38:18.918545Z","iopub.status.busy":"2024-03-31T09:38:18.918112Z","iopub.status.idle":"2024-03-31T09:38:18.926813Z","shell.execute_reply":"2024-03-31T09:38:18.925470Z","shell.execute_reply.started":"2024-03-31T09:38:18.918510Z"},"trusted":true},"outputs":[],"source":["'''\n","config = {\n","    \"epochs\" : 10,\n","    \"batch_size\": 64,\n","    'activation': 'relu',\n","    'learning_rate':0.001,\n","    \"dropout\": 0.3,\n","    \"batch_norm\": True,\n","    \"data_aug\": True,\n","    'size_filters':[7,5,5,3,3],\n","    'filter_organization': 2,\n","    'number_filters': 16,\n","    \"neurons_in_dense_layer\": 512\n","}\n","class DotDict:\n","    def __init__(self, dictionary):\n","        self.__dict__.update(dictionary)\n","\n","args = DotDict(config)\n","train(args)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:23.292348Z","iopub.status.busy":"2024-03-31T09:45:23.291980Z","iopub.status.idle":"2024-03-31T09:45:25.441004Z","shell.execute_reply":"2024-03-31T09:45:25.440056Z","shell.execute_reply.started":"2024-03-31T09:45:23.292318Z"},"trusted":true},"outputs":[],"source":["# wandb.login()\n","sweep_config = {\n","    \"name\" : \"Assignment2_Part_A_Q2\",\n","    \"method\" : \"bayes\",\n","    'metric': {\n","        'name': 'val_acc',\n","        'goal': 'maximize'\n","    },\n","    \"parameters\" : {\n","        'number_filters': {\n","            'values': [16, 32, 64, 128]\n","        },\n","        'activation': {\n","            'values': ['ReLU', 'LeakyReLU','GELU','SiLU','Mish','ELU']\n","        },\n","        'filter_organization': {\n","            'values': [1, 2, 0.5]\n","        },\n","        \"data_aug\": {\n","              \"values\": [True,False]\n","        },\n","        \"batch_norm\": {\n","              \"values\": [True,False]\n","        },\n","        \"dropout\": {\n","            \"values\": [0,0.1,0.2,0.3]\n","        },\n","        \"batch_size\": {\n","            \"values\": [32, 64, 128]\n","        },\n","        \"epochs\" : {\n","            \"values\" : [10, 15, 20 , 25 , 30]\n","        },\n","        'learning_rate':{\n","            \"values\": [0.001,0.0001,0.0003,0.0005]\n","        },\n","        'size_filters':{\n","            'values': [[7,5,5,3,3], [11,9,7,5,3]]\n","        },\n","        \"neurons_in_dense_layer\": {\n","            \"values\": [32, 64, 128, 256, 512, 1024]\n","        }        \n","    }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project=\"dl-assignment-2\", entity=\"cs23m007\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-31T09:45:33.633869Z","iopub.status.busy":"2024-03-31T09:45:33.632799Z","iopub.status.idle":"2024-03-31T09:53:47.758411Z","shell.execute_reply":"2024-03-31T09:53:47.757194Z","shell.execute_reply.started":"2024-03-31T09:45:33.633829Z"},"trusted":true},"outputs":[],"source":["wandb.agent(sweep_id, train, count = 50)\n","wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4693720,"sourceId":7975703,"sourceType":"datasetVersion"}],"dockerImageVersionId":30673,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
